doc	unit1_toks	unit2_toks	unit1_txt	unit2_txt	s1_toks	s2_toks	unit1_sent	unit2_sent	dir	rel_type	orig_label	label
GUM_podcast_llms	1-32	33-72	So there 's been a lot of hyperbole about AI , um , obviously a lot of things going on with OpenAI and ChatGPT and Bard and all these different things .	Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	1-32	33-72	So there 's been a lot of hyperbole about AI , um , obviously a lot of things going on with OpenAI and ChatGPT and Bard and all these different things .	Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	33-45	46-72	Um , but um there 's a lot of fear about AI ,	and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	33-72	33-72	Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	46-62	63-72	and what we thought we 'd do is get into what are these fears about AI ,	and do we think that they 're actually valid ?	33-72	33-72	Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ?	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	119-125,134-145	126-133	So yeah , first of all , <*> um , the large language model thing is mostly a joke ,	before we get into it , slightly ,	119-169	119-169	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	1<2	explicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	119-145	146-169	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke ,	but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	119-169	119-169	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	119-169	170-215	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	119-169	170-215	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	1<2	altlex	expansion.substitution.arg2-as-subst	expansion.substitution
GUM_podcast_llms	146-159	160-169	but I think it 's useful to talk about LLMs rather than AI ,	um , because it keeps the discussion more focused .	119-169	119-169	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	170-215	216-228	One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	It 's not really an interesting discussion because it 's not focused .	170-215	216-228	One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	It 's not really an interesting discussion because it 's not focused .	1<2	implicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	189-192	193-215	about AI takes over	and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	170-215	170-215	One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ?	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	216-222	223-228	It 's not really an interesting discussion	because it 's not focused .	216-228	216-228	It 's not really an interesting discussion because it 's not focused .	It 's not really an interesting discussion because it 's not focused .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	216-228	229-245	It 's not really an interesting discussion because it 's not focused .	But I think part of that is because everyone has a preconception for what AI is .	216-228	229-245	It 's not really an interesting discussion because it 's not focused .	But I think part of that is because everyone has a preconception for what AI is .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	229-245	263-308	But I think part of that is because everyone has a preconception for what AI is .	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	229-245	263-308	But I think part of that is because everyone has a preconception for what AI is .	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	1<2	explicit	comparison.contrast	comparison.contrast
GUM_podcast_llms	246-251	252-258	It 's the Star Trek computer	or it 's Hal or whatever .	246-258	246-258	It 's the Star Trek computer or it 's Hal or whatever .	It 's the Star Trek computer or it 's Hal or whatever .	1<2	explicit	expansion.disjunction	expansion.disjunction
GUM_podcast_llms	263,274-308	264-273	Whereas <*> then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	if we talk about large language models , LLMs ,	263-308	263-308	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	1<2	explicit	contingency.condition.arg2-as-cond	contingency.condition
GUM_podcast_llms	263,274-299	300-308	Whereas <*> then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think ,	and it defuses a lot of the conversation .	263-308	263-308	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	263-308	309-327	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	So I think it 's worth talking about LLMs specifically because that 's what we 're interested in .	263-308	309-327	Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation .	So I think it 's worth talking about LLMs specifically because that 's what we 're interested in .	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	309,312-318	319-327	So <*> it 's worth talking about LLMs specifically	because that 's what we 're interested in .	309-327	309-327	So I think it 's worth talking about LLMs specifically because that 's what we 're interested in .	So I think it 's worth talking about LLMs specifically because that 's what we 're interested in .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	309-327	330-359	So I think it 's worth talking about LLMs specifically because that 's what we 're interested in .	So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff .	309-327	330-359	So I think it 's worth talking about LLMs specifically because that 's what we 're interested in .	So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff .	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	330-336,344-359	337-343	So I put together a relatively -- <*> but a relatively detailed list of concerns that people have brought up about this stuff .	I -- it 's not comprehensive ,	330-359	330-359	So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff .	So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	330-359	360-371	So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff .	And I 'm interested in your thoughts on each of them .	330-359	360-371	So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff .	And I 'm interested in your thoughts on each of them .	1<2	explicit	expansion.level-of-detail.arg2-as-detail	expansion.level-of-detail
GUM_podcast_llms	360-371	372-407	And I 'm interested in your thoughts on each of them .	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	360-371	372-407	And I 'm interested in your thoughts on each of them .	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	372-407	408-433	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	And for pretty much all of them , the shedload of information that gets inhaled was n't owned by the people who did the inhaling .	372-407	408-433	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	And for pretty much all of them , the shedload of information that gets inhaled was n't owned by the people who did the inhaling .	1<2	explicit	expansion.level-of-detail.arg2-as-detail	expansion.level-of-detail
GUM_podcast_llms	389-393	394-407	where every LLM is built	by inhaling a shedload of information and then renting out access to it .	372-407	372-407	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	1<2	explicit	expansion.manner.arg2-as-manner	expansion.manner
GUM_podcast_llms	389-393	394-407	where every LLM is built	by inhaling a shedload of information and then renting out access to it .	372-407	372-407	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	1>2	explicit	contingency.purpose.arg1-as-goal	contingency.purpose
GUM_podcast_llms	394-399	400-407	by inhaling a shedload of information	and then renting out access to it .	372-407	372-407	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	394-399	400-407	by inhaling a shedload of information	and then renting out access to it .	372-407	372-407	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it .	1<2	explicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	434-460	461-504	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	434-460	461-504	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	434-460	461-504	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	434-460	461-504	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	1<2	explicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	444-453	454-460	about whether it 's reasonable to download the whole Internet	and shove it into your LLM .	434-460	434-460	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	444-453	454-460	about whether it 's reasonable to download the whole Internet	and shove it into your LLM .	434-460	434-460	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM .	1<2	implicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	461-504	509-516	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	But that 's one of the objections .	461-504	509-516	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	But that 's one of the objections .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	478-491	492-504	" this is our proprietary product that you 're not allowed access to ,	but we 'll charge you for access to it " or whatever .	461-504	461-504	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever .	1<2	explicit	comparison.contrast	comparison.contrast
GUM_podcast_llms	509-516	517-544	But that 's one of the objections .	And it 's it 's a particularly pointed one in the art world , um , for reasons that I 'd be interested in your thoughts on .	509-516	517-544	But that 's one of the objections .	And it 's it 's a particularly pointed one in the art world , um , for reasons that I 'd be interested in your thoughts on .	1<2	explicit	expansion.level-of-detail.arg2-as-detail	expansion.level-of-detail
GUM_podcast_llms	517-544	545-593	And it 's it 's a particularly pointed one in the art world , um , for reasons that I 'd be interested in your thoughts on .	But I will point out before we get to that , that the EU are putting together regulation which will require people who create LLMs to declare the copyrighted material that they used in the training corpora , which I think is a really neat solution to this .	517-544	545-593	And it 's it 's a particularly pointed one in the art world , um , for reasons that I 'd be interested in your thoughts on .	But I will point out before we get to that , that the EU are putting together regulation which will require people who create LLMs to declare the copyrighted material that they used in the training corpora , which I think is a really neat solution to this .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	545-549	550-555	But I will point out	before we get to that ,	545-593	545-593	But I will point out before we get to that , that the EU are putting together regulation which will require people who create LLMs to declare the copyrighted material that they used in the training corpora , which I think is a really neat solution to this .	But I will point out before we get to that , that the EU are putting together regulation which will require people who create LLMs to declare the copyrighted material that they used in the training corpora , which I think is a really neat solution to this .	1<2	explicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	594-637	638-649	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is .	They have to declare that they did it , which means --	594-637	638-649	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is .	They have to declare that they did it , which means --	1<2	explicit	comparison.contrast	comparison.contrast
GUM_podcast_llms	594-637	604-649	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is .	but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is . They have to declare that they did it , which means --	594-637	594-649	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is .	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is . They have to declare that they did it , which means --	1<2	explicit	comparison.contrast	comparison.contrast
GUM_podcast_llms	622-627	628-637	which almost everything on Earth is	and almost everything in the LLM models probably is .	594-637	594-637	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is .	They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	650-653	681-727	It seems fair .	Yeah and I agree with it for I think two reasons , one of which considerably more noble than the other . Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on .	650-653	681-727	It seems fair .	Yeah and I agree with it for I think two reasons , one of which considerably more noble than the other . Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	661-670	671-680	I do n't often agree with EU regulation stances ,	but this one I think is is very reasonable .	661-680	661-680	I do n't often agree with EU regulation stances , but this one I think is is very reasonable .	I do n't often agree with EU regulation stances , but this one I think is is very reasonable .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	703-727	728-750	Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on .	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	703-727	728-750	Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on .	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	703-727	728-750	Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on .	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	703-727	728-750	Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on .	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	728-750	809-897	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	And the second thing is this is the Schadenfreude one , which is not anywhere near as noble . I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	728-750	809-897	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	And the second thing is this is the Schadenfreude one , which is not anywhere near as noble . I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	728-750	751-773	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	728-750	751-773	Um , and this will also require the companies building LLMs to actually give a damn about where they get it from .	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	1<2	implicit	expansion.level-of-detail.arg2-as-detail	expansion.level-of-detail
GUM_podcast_llms	751-773	774-799	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	They 're gon na have to document where they got the information from , when they got it , what permissions they had to it .	751-773	774-799	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	They 're gon na have to document where they got the information from , when they got it , what permissions they had to it .	1>2	altlex	expansion.substitution.arg1-as-subst	expansion.substitution
GUM_podcast_llms	756-761	762-773	" just set a crawler going	and then whatever it pulls back , shove it in " .	751-773	751-773	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	756-761	762-773	" just set a crawler going	and then whatever it pulls back , shove it in " .	751-773	751-773	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " .	1<2	explicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	774-799	800-808	They 're gon na have to document where they got the information from , when they got it , what permissions they had to it .	And that can only be a good thing .	774-799	800-808	They 're gon na have to document where they got the information from , when they got it , what permissions they had to it .	And that can only be a good thing .	1<2	explicit	expansion.level-of-detail.arg2-as-detail	expansion.level-of-detail
GUM_podcast_llms	809-827	828-897	And the second thing is this is the Schadenfreude one , which is not anywhere near as noble .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	809-827	828-897	And the second thing is this is the Schadenfreude one , which is not anywhere near as noble .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	implicit	expansion.level-of-detail.arg2-as-detail	expansion.level-of-detail
GUM_podcast_llms	843-856	857-863	in between saying , " yeah , we used all this copyrighted information "	and getting beaten to death by Disney	828-897	828-897	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	843-863	864-897	in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney	or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	828-897	828-897	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	explicit	expansion.disjunction	expansion.disjunction
GUM_podcast_llms	864-887	888-897	or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney	and then getting beaten to death by the EU .	828-897	828-897	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	explicit	contingency.cause.result	contingency.cause
GUM_podcast_llms	864-887	888-897	or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney	and then getting beaten to death by the EU .	828-897	828-897	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	explicit	temporal.asynchronous.precedence	temporal.asynchronous
GUM_podcast_llms	864-879	880-887	or saying , " we 're not prepared to declare where we got this information "	to avoid being beaten to death by Disney	828-897	828-897	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU .	1<2	implicit	contingency.purpose.arg2-as-goal	contingency.purpose
GUM_podcast_llms	898-899,904-908	900-903	So , <*> not particularly noble motive ,	like I said ,	898-923	898-923	So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent .	So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent .	1<2	explicit	comparison.similarity	comparison.similarity
GUM_podcast_llms	898-908	909-923	So , like I said , not particularly noble motive ,	but I think , like you said , I think it 'd be transparent .	898-923	898-923	So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent .	So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	913-916	917-918	like you said ,	I think	898-923	898-923	So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent .	So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent .	1<2	explicit	comparison.similarity	comparison.similarity
GUM_podcast_llms	924-925	926-927	Yes ?	Right .	924-925	926-927	Yes ?	Right .	1<2	hypophora	hypophora	hypophora
GUM_podcast_llms	935-945	946-957	Do we want to go through these one by one ,	or do you want to just get them all out first ?	935-957	935-957	Do we want to go through these one by one , or do you want to just get them all out first ?	Do we want to go through these one by one , or do you want to just get them all out first ?	1<2	explicit	expansion.disjunction	expansion.disjunction
GUM_podcast_llms	935-957	958-975	Do we want to go through these one by one , or do you want to just get them all out first ?	I think -- I -- I do n't know , what do you think we could do ?	935-957	958-975	Do we want to go through these one by one , or do you want to just get them all out first ?	I think -- I -- I do n't know , what do you think we could do ?	1<2	hypophora	hypophora	hypophora
GUM_podcast_llms	935-1001	1002-1033	Do we want to go through these one by one , or do you want to just get them all out first ? I think -- I -- I do n't know , what do you think we could do ? I mean , are we covered on that one or have you got lots more thoughts about the source of training material for the LLMs ?	I mean , that seems uncontroversial to me . Um , just -- just require them to declare where they got the copyright . I suspect OpenAI will disagree with you .	935-1001	1002-1033	Do we want to go through these one by one , or do you want to just get them all out first ? I think -- I -- I do n't know , what do you think we could do ? I mean , are we covered on that one or have you got lots more thoughts about the source of training material for the LLMs ?	I mean , that seems uncontroversial to me . Um , just -- just require them to declare where they got the copyright . I suspect OpenAI will disagree with you .	1<2	hypophora	hypophora	hypophora
GUM_podcast_llms	979-984	985-1001	are we covered on that one	or have you got lots more thoughts about the source of training material for the LLMs ?	976-1001	976-1001	I mean , are we covered on that one or have you got lots more thoughts about the source of training material for the LLMs ?	I mean , are we covered on that one or have you got lots more thoughts about the source of training material for the LLMs ?	1<2	explicit	expansion.disjunction	expansion.disjunction
GUM_podcast_llms	1057-1069	1070-1078	We , the three of us do n't agree on a lot ,	but I suspect this is one of them .	1057-1078	1057-1078	We , the three of us do n't agree on a lot , but I suspect this is one of them .	We , the three of us do n't agree on a lot , but I suspect this is one of them .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	1079-1096	1116-1144	I -- I -- see , I think OpenAI , I do n't know if they disagree .	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	1079-1096	1116-1144	I -- I -- see , I think OpenAI , I do n't know if they disagree .	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	1>2	explicit	comparison.concession.arg1-as-denier	comparison.concession
GUM_podcast_llms	1079-1096	1097-1115	I -- I -- see , I think OpenAI , I do n't know if they disagree .	They would n't like to say they agree because they know it 's just unilaterally bad for them .	1079-1096	1097-1115	I -- I -- see , I think OpenAI , I do n't know if they disagree .	They would n't like to say they agree because they know it 's just unilaterally bad for them .	1<2	implicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	1097-1104	1105-1115	They would n't like to say they agree	because they know it 's just unilaterally bad for them .	1097-1115	1097-1115	They would n't like to say they agree because they know it 's just unilaterally bad for them .	They would n't like to say they agree because they know it 's just unilaterally bad for them .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	1116-1144	1291-1311	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	And and exactly the reason for this is that they know they have n't got a leg to stand on .	1116-1144	1291-1311	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	And and exactly the reason for this is that they know they have n't got a leg to stand on .	1<2	explicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	1116-1144	1145-1185	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	He explicitly avoided this topic , which , given the amount of prep I 'm sure went into testifying in front of Congress for the first time -- him leaving that out was , I imagine , not an oversight .	1116-1144	1145-1185	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	He explicitly avoided this topic , which , given the amount of prep I 'm sure went into testifying in front of Congress for the first time -- him leaving that out was , I imagine , not an oversight .	1<2	implicit	comparison.contrast	comparison.contrast
GUM_podcast_llms	1131-1136	1137-1144	that AI should be regulated ,	that the models should be regulated etc. etc.	1116-1144	1116-1144	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc.	1<2	implicit	expansion.conjunction	expansion.conjunction
GUM_podcast_llms	1151-1152,1173-1185	1153-1172	which , <*> him leaving that out was , I imagine , not an oversight .	given the amount of prep I 'm sure went into testifying in front of Congress for the first time --	1145-1185	1145-1185	He explicitly avoided this topic , which , given the amount of prep I 'm sure went into testifying in front of Congress for the first time -- him leaving that out was , I imagine , not an oversight .	He explicitly avoided this topic , which , given the amount of prep I 'm sure went into testifying in front of Congress for the first time -- him leaving that out was , I imagine , not an oversight .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	1228-1234	1235-1240	very famously asked for more crypto regulation	while being a total grifter .	1221-1240	1221-1240	Look at Sam Bankman - Fried , very famously asked for more crypto regulation while being a total grifter .	Look at Sam Bankman - Fried , very famously asked for more crypto regulation while being a total grifter .	1<2	explicit	temporal.synchronous	temporal.synchronous
GUM_podcast_llms	1278-1286	1287-1290	that I 'm expecting Jeremy Corbyn to come in	singing about it .	1261-1290	1261-1290	Um , avoiding talking about this particular topic is the reddest of flags , to the point that I 'm expecting Jeremy Corbyn to come in singing about it .	Um , avoiding talking about this particular topic is the reddest of flags , to the point that I 'm expecting Jeremy Corbyn to come in singing about it .	1<2	implicit	expansion.manner.arg2-as-manner	expansion.manner
GUM_podcast_llms	1291-1311	1312-1313	And and exactly the reason for this is that they know they have n't got a leg to stand on .	Right ?	1291-1311	1312-1313	And and exactly the reason for this is that they know they have n't got a leg to stand on .	Right ?	1<2	implicit	expansion.equivalence	expansion.equivalence
GUM_podcast_llms	1312-1313	1314-1333	Right ?	Well , I -- in my opinion , at least they have n't got a leg to stand on .	1312-1313	1314-1333	Right ?	Well , I -- in my opinion , at least they have n't got a leg to stand on .	1<2	hypophora	hypophora	hypophora
GUM_podcast_llms	1334-1364	1365-1392	So we all agree that that , that people building , um , large language models should have to declare where they got all the data from , from it .	And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that .	1334-1364	1365-1392	So we all agree that that , that people building , um , large language models should have to declare where they got all the data from , from it .	And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that .	1<2	explicit	comparison.contrast	comparison.contrast
GUM_podcast_llms	1365,1386-1392	1366-1385	And <*> then they can stop doing that .	if they find themselves in a position where they do n't want to do that because they 'll lose ,	1365-1392	1365-1392	And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that .	And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that .	1<2	explicit	contingency.condition.arg2-as-cond	contingency.condition
GUM_podcast_llms	1373-1380	1381-1385	where they do n't want to do that	because they 'll lose ,	1365-1392	1365-1392	And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that .	And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	1395-1418	1419-1432	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine ,	but I do n't I do n't think we want to get into that	1395-1442	1395-1442	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI .	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI .	1<2	explicit	comparison.concession.arg2-as-denier	comparison.concession
GUM_podcast_llms	1395-1432	1433-1442	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that	because it 's got nothing to do with AI .	1395-1442	1395-1442	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI .	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI .	1<2	explicit	contingency.cause.reason	contingency.cause
GUM_podcast_llms	1395-1442	1443-1450	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI .	Yeah , it 's kind of irrelevant .	1395-1442	1443-1450	I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI .	Yeah , it 's kind of irrelevant .	1<2	implicit	expansion.equivalence	expansion.equivalence
