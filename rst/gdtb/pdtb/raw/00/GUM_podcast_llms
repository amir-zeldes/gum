So there 's been a lot of hyperbole about AI , um , obviously a lot of things going on with OpenAI and ChatGPT and Bard and all these different things . Um , but um there 's a lot of fear about AI , and what we thought we 'd do is get into what are these fears about AI , and do we think that they 're actually valid ? Um , so one of those nice specific topics that we tend to cover on on Bad Voltage , but why do n't you Mr. Large Language Model run through some of these fears that people have been digging into . Some of the concerns . So yeah , first of all , before we get into it , slightly , um , the large language model thing is mostly a joke , but I think it 's useful to talk about LLMs rather than AI , um , because it keeps the discussion more focused . One of the concerns which we 're not really gon na talk about is the sci - fi one about AI takes over and turns the whole world into a machine for making paperclips and grey goo , and it -- just whatever , right ? It 's not really an interesting discussion because it 's not focused . But I think part of that is because everyone has a preconception for what AI is . It 's the Star Trek computer or it 's Hal or whatever . Yeah , yeah . Whereas if we talk about large language models , LLMs , then it 's clear that we 're talking about a specific technology rather than the sort of general nebulous concept of computers that can think , and it defuses a lot of the conversation . So I think it 's worth talking about LLMs specifically because that 's what we 're interested in . Yeah . So I put together a relatively -- I -- it 's not comprehensive , but a relatively detailed list of concerns that people have brought up about this stuff . And I 'm interested in your thoughts on each of them . So in no particular order , there 's what you might call the free software complaint , where every LLM is built by inhaling a shedload of information and then renting out access to it . And for pretty much all of them , the shedload of information that gets inhaled was n't owned by the people who did the inhaling . Um , there 's there 's a big open question about whether it 's reasonable to download the whole Internet and shove it into your LLM . And then there 's a second question about whether having done that , whether you can go " this is our proprietary product that you 're not allowed access to , but we 'll charge you for access to it " or whatever . Um , yeah . But that 's one of the objections . And it 's it 's a particularly pointed one in the art world , um , for reasons that I 'd be interested in your thoughts on . But I will point out before we get to that , that the EU are putting together regulation which will require people who create LLMs to declare the copyrighted material that they used in the training corpora , which I think is a really neat solution to this . They 're not saying you ca n't do this , but they 're just saying , yeah , if you -- if you brought in copyrighted material , which almost everything on Earth is and almost everything in the LLM models probably is . They have to declare that they did it , which means -- It seems fair . It seems absolutely fair to me . I do n't often agree with EU regulation stances , but this one I think is is very reasonable . Yeah and I agree with it for I think two reasons , one of which considerably more noble than the other . Um , the noble reason is , I think it 's good to provide transparency on where the data came from and so on . Um , and this will also require the companies building LLMs to actually give a damn about where they get it from . They ca n't just go " just set a crawler going and then whatever it pulls back , shove it in " . They 're gon na have to document where they got the information from , when they got it , what permissions they had to it . And that can only be a good thing . And the second thing is this is the Schadenfreude one , which is not anywhere near as noble . I am enjoying the idea of watching people at huge companies who build LLMs dancing in between saying , " yeah , we used all this copyrighted information " and getting beaten to death by Disney or saying , " we 're not prepared to declare where we got this information " to avoid being beaten to death by Disney and then getting beaten to death by the EU . So , like I said , not particularly noble motive , but I think , like you said , I think it 'd be transparent . Yes ? Right . Alright , so that 's one . Do we want to go through these one by one , or do you want to just get them all out first ? I think -- I -- I do n't know , what do you think we could do ? I mean , are we covered on that one or have you got lots more thoughts about the source of training material for the LLMs ? I mean , that seems uncontroversial to me . Um , just -- just require them to declare where they got the copyright . I suspect OpenAI will disagree with you . I think the three of us will tend to agree on this one , oddly . Yeah , yeah , I agree . We , the three of us do n't agree on a lot , but I suspect this is one of them . I -- I -- see , I think OpenAI , I do n't know if they disagree . They would n't like to say they agree because they know it 's just unilaterally bad for them . But Altman testified in front of Congress yesterday , said a whole bunch of things that AI should be regulated , that the models should be regulated etc. etc. He explicitly avoided this topic , which , given the amount of prep I 'm sure went into testifying in front of Congress for the first time -- him leaving that out was , I imagine , not an oversight . Yeah , it is the best I 've ever seen . I was gon na say first time I 've ever seen a tech company ask for more regulation . That 's not true . Look at Sam Bankman - Fried , very famously asked for more crypto regulation while being a total grifter . That 's -- that 's fine . I -- look at how well it worked out for that guy . Um , avoiding talking about this particular topic is the reddest of flags , to the point that I 'm expecting Jeremy Corbyn to come in singing about it . And and exactly the reason for this is that they know they have n't got a leg to stand on . Right ? Well , I -- in my opinion , at least they have n't got a leg to stand on . So we all agree that that , that people building , um , large language models should have to declare where they got all the data from , from it . And if they find themselves in a position where they do n't want to do that because they 'll lose , then they can stop doing that . Yeah . I mean , there i- there is a related conversation around searchability of information like how Google handles this with the search engine , but I do n't I do n't think we want to get into that because it 's got nothing to do with AI . Yeah , it 's kind of irrelevant . Nothing to do with it . It 's kind of related to the topic . Yeah , exactly .